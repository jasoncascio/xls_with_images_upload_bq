{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "XLS Uploader 10-31-2024"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-magic\n",
        "\n",
        "from google.cloud import storage\n",
        "from google.cloud.storage.bucket import Bucket\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import openpyxl\n",
        "from openpyxl.worksheet.worksheet import Worksheet\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import pathlib\n",
        "import magic\n",
        "import re\n",
        "import io\n",
        "import json\n",
        "import base64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JigzdRssKZQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730476523976,
          "user_tz": 240,
          "elapsed": 3879,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d8f919c1-cb1b-4a32-f57d-b3e62e9e39a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (0.4.27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenpyxlSheetImages:\n",
        "    \"\"\"\n",
        "    Class assumes:\n",
        "      Sheets have column headers in the first row (no offset)\n",
        "      The first column is used for data (no offset)\n",
        "      All public methods are 1-indexed\n",
        "      This class is for reading xls only\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sheet: Worksheet):\n",
        "        self._images = [OpenpyxlSheetImage(image) for image in sheet._images]\n",
        "        self.num_rows = sheet.max_row - 1     # discount header\n",
        "        self.num_columns = sheet.max_column\n",
        "        self.columns_with_images = self._set_columns_with_images() # 1-indexed\n",
        "\n",
        "    def _set_columns_with_images(self):\n",
        "        aggregator = {}\n",
        "        for col_idx in range(1, self.num_columns + 1): # maintain 1-index\n",
        "            if set(self.get_images_by_column(col_idx)) != {None}:\n",
        "                aggregator[col_idx] = True\n",
        "\n",
        "        return list(aggregator.keys())\n",
        "\n",
        "    def get_images(self):\n",
        "        return self._images\n",
        "\n",
        "    def get_columns_with_images(self):\n",
        "        return self.columns_with_images\n",
        "\n",
        "    def get_images_by_column(self, column: int, as_b64=False):\n",
        "        return_array = [None] * self.num_rows\n",
        "        images = [image for image in self._images if image.column + 1 == column]\n",
        "\n",
        "        for row_index, item in enumerate(return_array):\n",
        "            for image in images:\n",
        "                if image.row == row_index:      # both are 0-indexed\n",
        "                    img = base64.b64encode(image.image_bytes) if as_b64 else image\n",
        "                    return_array[row_index] = img\n",
        "\n",
        "        return return_array\n",
        "\n",
        "\n",
        "    def get_unique_image_names_by_column(self, column: int):\n",
        "        column_data = self.get_images_by_column(column)\n",
        "\n",
        "        for index, image in enumerate(column_data):\n",
        "            if image:\n",
        "                column_data[index] = image.unique_file_name\n",
        "\n",
        "        return column_data\n",
        "\n",
        "\n",
        "class OpenpyxlSheetImage:\n",
        "\n",
        "    def __init__(self, image):\n",
        "        self.image_bytes = image._data()          # done this way to sidestep io problem\n",
        "        self.image_type = image.format            # e.g. png\n",
        "        self.row = image.anchor._from.row         # 0-indexed\n",
        "        self.column = image.anchor._from.col      # 0-indexed\n",
        "        self.path = image.path\n",
        "        self.mime_type = magic.from_buffer(self.image_bytes, mime=True)\n",
        "        self.file_name = pathlib.Path(self.path).name\n",
        "        self.unique_file_name = self._set_unique_filename()\n",
        "\n",
        "    def _set_unique_filename(self, delimiter: str='-'):\n",
        "        return pathlib.Path(self.file_name).stem + delimiter + uuid.uuid4().hex + '.' + self.image_type"
      ],
      "metadata": {
        "id": "mUE798qcffKa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730476525524,
          "user_tz": 240,
          "elapsed": 239,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_safe_table_name(blobname: str):\n",
        "    file_stem = pathlib.Path(blobname).stem\n",
        "    table_name = file_stem.replace(\" \", \"_\")\n",
        "    table_name = re.sub(r'[^a-zA-Z0-9_]', '', table_name)\n",
        "    table_name = table_name.lower()\n",
        "    if not table_name[0].isalpha():\n",
        "        table_name = \"table_\" + table_name\n",
        "\n",
        "    return table_name\n",
        "\n",
        "def load_dataframe_to_bq(\n",
        "    df: pd.DataFrame,\n",
        "    full_table_id: str,\n",
        "    write_disp: str=bigquery.enums.WriteDisposition.WRITE_APPEND):\n",
        "\n",
        "    client = bigquery.Client()\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        write_disposition=write_disp,\n",
        "    )\n",
        "\n",
        "    job = client.load_table_from_dataframe(\n",
        "        df, full_table_id, job_config=job_config\n",
        "    )  # Make an API request.\n",
        "    job.result()  # Wait for the job to complete.\n",
        "\n",
        "    table = client.get_table(full_table_id)\n",
        "    print(\n",
        "        \"Loaded {} rows and {} columns to {}\".format(\n",
        "            df.shape[0], len(table.schema), full_table_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "def delete_images(bucket: Bucket, image_names_list: list=[]):\n",
        "    successful_deletes = []\n",
        "    had_failure = False\n",
        "\n",
        "    try:\n",
        "        for image_name in image_names_list:\n",
        "            bucket.delete_blob(image_name)\n",
        "            successful_deletes.append(image_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        had_failure = True\n",
        "        print(e)\n",
        "\n",
        "    print('Successfully deleted from '+ bucket.name + ' ' + json.dumps(successful_deletes))\n",
        "    return successful_deletes, had_failure\n",
        "\n",
        "\n",
        "def store_images(bucket: Bucket, image_handler: OpenpyxlSheetImages):\n",
        "    successful_uploads = []\n",
        "    had_failure = False\n",
        "\n",
        "    images = image_handler.get_images()\n",
        "    try:\n",
        "        for image in images:\n",
        "          blob=bucket.blob(image.unique_file_name)\n",
        "          blob.upload_from_string(\n",
        "                data=image.image_bytes,\n",
        "                content_type=image.mime_type,\n",
        "                num_retries=3\n",
        "          )\n",
        "          successful_uploads.append(image.unique_file_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        had_failure = True\n",
        "        print(e)\n",
        "\n",
        "    print('Successfully stored to '+ bucket.name + ' ' + json.dumps(successful_uploads))\n",
        "    return successful_uploads, had_failure"
      ],
      "metadata": {
        "id": "5h6W-7W0mcJD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730476530060,
          "user_tz": 240,
          "elapsed": 195,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenpyxlSheetHeaderHelper:\n",
        "    \"\"\"\n",
        "    Class assumes:\n",
        "      All public methods are 1-indexed\n",
        "      This class is for reading xls only\n",
        "    \"\"\"\n",
        "    def __init__(self, sheet: Worksheet):\n",
        "        self.column_names = self._set_column_names(sheet)\n",
        "        self.safe_column_names = self._set_safe_column_names()\n",
        "\n",
        "    def _set_column_names(self, sheet: Worksheet) -> list:\n",
        "        columns = []\n",
        "        for row in sheet.iter_rows(min_row=1, max_row=1):\n",
        "            for cell in row:\n",
        "                columns.append(cell.value)\n",
        "\n",
        "        return columns\n",
        "\n",
        "    def _set_safe_column_names(self):\n",
        "        return [self.get_safe_column_name(name) for name in self.column_names]\n",
        "\n",
        "    def get_safe_column_name(self, unsafe_name: str):\n",
        "        safe_name = unsafe_name.replace(\" \", \"_\")\n",
        "        safe_name = re.sub(r'[^a-zA-Z0-9_]', '', safe_name)\n",
        "        safe_name = safe_name.lower()\n",
        "        if not safe_name[0].isalpha():\n",
        "            safe_name = \"col_\" + safe_name\n",
        "\n",
        "        return safe_name\n",
        "\n",
        "    def get_column_names(self, safe_names: bool=False):\n",
        "        return self.safe_column_names if safe_names else self.column_names\n",
        "\n",
        "    def get_column_name_by_index(self, idx: int, safe_names: bool=False):\n",
        "        return self.get_column_names(safe_names)[idx - 1]\n",
        "\n",
        "    def get_index_by_column_name(self, column_name: int, safe_names: bool=False):\n",
        "        the_list = (self.safe_column_names if safe_names else self.column_names)\n",
        "\n",
        "        return the_list.index(column_name) + 1  # maintain 1-index\n",
        "\n",
        "    def get_pandas_rename_dict(self):\n",
        "        rename_dict = {}\n",
        "        for idx, column in enumerate(self.column_names):\n",
        "            rename_dict[column] = self.safe_column_names[idx]\n",
        "\n",
        "        return rename_dict"
      ],
      "metadata": {
        "id": "yt5ExtLQyhCE",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730476532100,
          "user_tz": 240,
          "elapsed": 218,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONST_PROJECT_NAME = '<your project name>'\n",
        "CONST_BQ_DATASET_NAME = '<your dataset name>'\n",
        "CONST_IMAGE_PROCESSED_BUCKET_NAME = '<your object bucket name>'\n",
        "\n",
        "\n",
        "TEST_EVENT_DATA = {\n",
        "    \"updated\": \"2024-10-23T19:06:39.349Z\",\n",
        "    \"kind\": \"storage#object\",\n",
        "    \"generation\": \"1729710399346045\",\n",
        "    \"bucket\": \"ingestion-demo-landing-test-bucket\",\n",
        "    \"etag\": \"CP2qq6+ZpYkDEAE=\",\n",
        "    \"contentType\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "    \"md5Hash\": \"5hwHeX38TuK31NFmTWmXNQ==\",\n",
        "    \"size\": \"4567895\",\n",
        "    \"metageneration\": \"1\",\n",
        "    \"timeCreated\": \"2024-10-23T19:06:39.349Z\",\n",
        "    \"timeStorageClassUpdated\": \"2024-10-23T19:06:39.349Z\",\n",
        "    \"crc32c\": \"yVwtNA==\",\n",
        "    \"name\": \"CDD Excel Export - cmpd registration.xlsx\",\n",
        "    \"storageClass\": \"STANDARD\"\n",
        "}\n",
        "TEST_CLOUD_EVENT = {\n",
        "    \"data\": TEST_EVENT_DATA\n",
        "}"
      ],
      "metadata": {
        "id": "gDns2DLtzKLt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730476534161,
          "user_tz": 240,
          "elapsed": 201,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(cloud_event):\n",
        "\n",
        "    # Event data\n",
        "    event_data = cloud_event['data']\n",
        "    file_name = event_data['name']\n",
        "    time_created = event_data['timeCreated']\n",
        "\n",
        "\n",
        "    # Storage Client / Buckets\n",
        "    storage_client = storage.Client()\n",
        "    landing_bucket = storage_client.get_bucket(event_data['bucket'])\n",
        "    image_processed_bucket = storage_client.get_bucket(CONST_IMAGE_PROCESSED_BUCKET_NAME)\n",
        "\n",
        "    # Get xls\n",
        "    buffer = io.BytesIO()\n",
        "    the_file_blob = landing_bucket.get_blob(event_data['name'])\n",
        "    the_file = the_file_blob.download_to_file(buffer)\n",
        "\n",
        "    # Openpyxl\n",
        "    wb = openpyxl.load_workbook(buffer)\n",
        "    default_sheet = wb.sheetnames[0]\n",
        "    sheet = wb[default_sheet]\n",
        "\n",
        "    # Special Handlers\n",
        "    image_handler = OpenpyxlSheetImages(sheet)\n",
        "    header_helper = OpenpyxlSheetHeaderHelper(sheet)\n",
        "\n",
        "    ######################################\n",
        "    # Handle table data - load dataframe\n",
        "    df = pd.read_excel(buffer)\n",
        "\n",
        "    # Process Dataframe step 1: patch in unique filenames into columns images were extracted from\n",
        "    col_idx_with_images = image_handler.get_columns_with_images()\n",
        "\n",
        "    for col_idx in col_idx_with_images:\n",
        "        column_name = header_helper.get_column_name_by_index(col_idx)\n",
        "        b64_column_name = header_helper.get_safe_column_name(column_name) + '_base64'\n",
        "\n",
        "        df[column_name] = image_handler.get_unique_image_names_by_column(col_idx)\n",
        "        df[b64_column_name] = image_handler.get_images_by_column(col_idx, as_b64=True)\n",
        "\n",
        "    # Process Dataframe step 2: rename columns to safe value\n",
        "    column_rename_dict = header_helper.get_pandas_rename_dict()\n",
        "    df.rename(columns = column_rename_dict, inplace = True)\n",
        "\n",
        "    # Load to BQ\n",
        "    full_table_id = '{}.{}.{}'.format(\n",
        "        CONST_PROJECT_NAME,\n",
        "        CONST_BQ_DATASET_NAME,\n",
        "        get_safe_table_name(file_name),\n",
        "    )\n",
        "\n",
        "    load_dataframe_to_bq(df, full_table_id)\n",
        "\n",
        "\n",
        "    ######################################\n",
        "    # Attempt upload of images\n",
        "    uploaded_image_list, load_had_failure = store_images(\n",
        "        bucket=image_processed_bucket,\n",
        "        image_handler=image_handler\n",
        "    )\n",
        "\n",
        "    if load_had_failure:\n",
        "\n",
        "      deleted_image_list, del_had_failure = delete_images(\n",
        "          bucket=image_processed_bucket,\n",
        "          image_names_list=uploaded_image_list\n",
        "      )\n",
        "\n",
        "      if del_had_failure:\n",
        "        diff = list(set(uploaded_image_list).difference(set(deleted_image_list)))\n",
        "        raise Exception('image uploads failed, manually delete '+json.dumps(diff))\n",
        "\n",
        "\n",
        "    # TODO:\n",
        "    # Add rollback if BQ save fails\n",
        "    # Add ingest time to processed file name and move into processed bucket\n",
        "\n",
        "\n",
        "main(TEST_CLOUD_EVENT)"
      ],
      "metadata": {
        "id": "XWA1c9npIeMg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730478677731,
          "user_tz": 240,
          "elapsed": 41142,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7e0919-0926-4085-a405-9197ade6aeb6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 499 rows and 8 columns to project.dataset.table\n",
            "Successfully stored to object-table-bucket [\"image1-4f8a1544e0e3427c87ed8b25cba977e7.png\", \"image1-187c3d40a8c64d42bc35c2e3b1424deb.png\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## For the deletion of test images - easier than deleting files from the console\n",
        "storage_client = storage.Client()\n",
        "landing_bucket = storage_client.get_bucket(CONST_IMAGE_PROCESSED_BUCKET_NAME)\n",
        "blobs = landing_bucket.list_blobs()\n",
        "\n",
        "landing_bucket.delete_blobs([blob.name for blob in blobs])\n",
        "\n",
        "\n",
        "# client = bigquery.Client()\n",
        "#     job_config = bigquery.LoadJobConfig(\n",
        "#         write_disposition=write_disp,\n",
        "#     )\n",
        "\n",
        "#     job = client.load_table_from_dataframe(\n",
        "#         df, full_table_id, job_config=job_config\n",
        "#     )  # Make an API request.\n",
        "#     job.result()  # Wait for the job to complete."
      ],
      "metadata": {
        "id": "IE9Seh7q0nqx",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730482305285,
          "user_tz": 240,
          "elapsed": 22552,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHdJsKjfuHeG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1729793396375,
          "user_tz": 240,
          "elapsed": 193,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a63614a4-0c06-437c-949b-cf647d817add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    }
  ]
}
